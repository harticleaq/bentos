service: service:LLM
name: qqwen
version: gb7l2zrevcypeusu
bentoml_version: 1.4.8
creation_time: '2025-04-29T03:15:25.842568+00:00'
labels:
  aliases: 0.5b
  generator: openllm
  owner: bentoml-team
models: []
entry_service: qqwen0.5b
services:
- name: qqwen0.5b
  service: ''
  models:
  - tag: sarad777--xmodel777:3aced482919079fb796dd31394743f6a
    module: null
    creation_time: '2025-04-29T03:15:24.475120+00:00'
    registry: huggingface
    metadata:
      model_id: sarad777/xmodel777
      revision: 9419c7e43c89ebef282bfc8d5648cd814252bc40
      endpoint: https://huggingface.co
      include: null
      exclude:
      - '*.pth'
      - '*.pt'
      - original/**/*
  dependencies: []
  config:
    name: qqwen0.5b
    traffic:
      timeout: 300
    resources:
      gpu: 1
      gpu_type: nvidia-l4
envs:
- name: UV_NO_PROGRESS
  value: '1'
- name: HF_HUB_DISABLE_PROGRESS_BARS
  value: '1'
- name: VLLM_ATTENTION_BACKEND
  value: FLASH_ATTN
- name: VLLM_USE_V1
  value: '1'
- name: UV_NO_PROGRESS
  value: '1'
- name: HF_HUB_DISABLE_PROGRESS_BARS
  value: '1'
- name: VLLM_ATTENTION_BACKEND
  value: FLASH_ATTN
- name: VLLM_USE_V1
  value: '1'
schema:
  name: qqwen0.5b
  type: service
  routes:
  - name: generate
    route: /generate
    batchable: false
    input:
      properties:
        prompt:
          default: Who are you? Please respond in pirate speak!
          title: Prompt
          type: string
        max_tokens:
          default: 1024
          maximum: 1024
          minimum: 128
          title: Max Tokens
          type: integer
      title: Input
      type: object
    output:
      type: string
      is_stream: true
      media_type: text/event-stream
    is_task: false
args: {}
spec: 2
image:
  base_image: python:3.11-slim
  python_version: '3.11'
  commands:
  - apt-get update && apt-get install -q -y --no-install-recommends --allow-remove-essential
    ca-certificates gnupg2 bash build-essential git
  python_requirements: '--index-url https://pypi.org/simple


    a2wsgi==1.10.8

    aiohappyeyeballs==2.6.1

    aiohttp==3.11.18

    aiosignal==1.3.2

    aiosqlite==0.21.0

    airportsdata==20250224

    annotated-types==0.7.0

    anyio==4.9.0

    appdirs==1.4.4

    asgiref==3.8.1

    astor==0.8.1

    attrs==25.3.0

    bentoml==1.4.8

    blake3==1.0.4

    cachetools==5.5.2

    cattrs==23.1.2

    certifi==2025.4.26

    charset-normalizer==3.4.1

    click==8.1.8

    click-option-group==0.5.7

    cloudpickle==3.1.1

    compressed-tensors==0.9.3

    cupy-cuda12x==13.4.1

    deprecated==1.2.18

    depyf==0.18.0

    dill==0.4.0

    diskcache==5.6.3

    distro==1.9.0

    dnspython==2.7.0

    einops==0.8.1

    email-validator==2.2.0

    fastapi==0.115.12

    fastapi-cli==0.0.7

    fastrlock==0.8.3

    filelock==3.18.0

    frozenlist==1.6.0

    fs==2.4.16

    fsspec==2025.3.2

    gguf==0.16.2

    googleapis-common-protos==1.70.0

    grpcio==1.71.0

    h11==0.16.0

    hf-xet==1.0.5

    httpcore==1.0.9

    httptools==0.6.4

    httpx==0.28.1

    httpx-ws==0.7.2

    huggingface-hub==0.30.2

    idna==3.10

    importlib-metadata==8.0.0

    interegular==0.3.3

    jinja2==3.1.6

    jiter==0.9.0

    jsonschema==4.23.0

    jsonschema-specifications==2025.4.1

    kantoku==0.18.3

    lark==1.2.2

    llguidance==0.7.19

    llvmlite==0.44.0

    lm-format-enforcer==0.10.11

    markdown-it-py==3.0.0

    markupsafe==3.0.2

    mdurl==0.1.2

    mistral-common==1.5.4

    mpmath==1.3.0

    msgpack==1.1.0

    msgspec==0.19.0

    multidict==6.4.3

    nest-asyncio==1.6.0

    networkx==3.4.2

    ninja==1.11.1.4

    numba==0.61.2

    numpy==2.2.5

    nvidia-cublas-cu12==12.4.5.8

    nvidia-cuda-cupti-cu12==12.4.127

    nvidia-cuda-nvrtc-cu12==12.4.127

    nvidia-cuda-runtime-cu12==12.4.127

    nvidia-cudnn-cu12==9.1.0.70

    nvidia-cufft-cu12==11.2.1.3

    nvidia-curand-cu12==10.3.5.147

    nvidia-cusolver-cu12==11.6.1.9

    nvidia-cusparse-cu12==12.3.1.170

    nvidia-cusparselt-cu12==0.6.2

    nvidia-ml-py==12.570.86

    nvidia-nccl-cu12==2.21.5

    nvidia-nvjitlink-cu12==12.4.127

    nvidia-nvtx-cu12==12.4.127

    openai==1.73.0

    opencv-python-headless==4.11.0.86

    opentelemetry-api==1.26.0

    opentelemetry-exporter-otlp==1.26.0

    opentelemetry-exporter-otlp-proto-common==1.26.0

    opentelemetry-exporter-otlp-proto-grpc==1.26.0

    opentelemetry-exporter-otlp-proto-http==1.26.0

    opentelemetry-instrumentation==0.47b0

    opentelemetry-instrumentation-aiohttp-client==0.47b0

    opentelemetry-instrumentation-asgi==0.47b0

    opentelemetry-proto==1.26.0

    opentelemetry-sdk==1.26.0

    opentelemetry-semantic-conventions==0.47b0

    opentelemetry-semantic-conventions-ai==0.4.3

    opentelemetry-util-http==0.47b0

    outlines==0.1.11

    outlines-core==0.1.26

    packaging==25.0

    partial-json-parser==0.2.1.1.post5

    pathspec==0.12.1

    pillow==11.2.1

    pip-requirements-parser==32.0.1

    prometheus-client==0.21.1

    prometheus-fastapi-instrumentator==7.1.0

    prompt-toolkit==3.0.51

    propcache==0.3.1

    protobuf==4.25.7

    psutil==7.0.0

    py-cpuinfo==9.0.0

    pycountry==24.6.1

    pydantic==2.11.3

    pydantic-core==2.33.1

    pygments==2.19.1

    pyparsing==3.2.3

    python-dateutil==2.9.0.post0

    python-dotenv==1.1.0

    python-json-logger==3.3.0

    python-multipart==0.0.20

    pyyaml==6.0.2

    pyzmq==26.4.0

    questionary==2.1.0

    ray==2.43.0

    referencing==0.36.2

    regex==2024.11.6

    requests==2.32.3

    rich==14.0.0

    rich-toolkit==0.14.3

    rpds-py==0.24.0

    safetensors==0.5.3

    schema==0.7.7

    scipy==1.15.2

    sentencepiece==0.2.0

    setuptools==80.0.0

    shellingham==1.5.4

    simple-di==0.1.5

    six==1.17.0

    sniffio==1.3.1

    starlette==0.46.2

    sympy==1.13.1

    tiktoken==0.9.0

    tokenizers==0.21.1

    tomli-w==1.2.0

    torch==2.6.0

    torchaudio==2.6.0

    torchvision==0.21.0

    tornado==6.4.2

    tqdm==4.67.1

    transformers==4.51.3

    triton==3.2.0

    typer==0.15.3

    typing-extensions==4.13.2

    typing-inspection==0.4.0

    urllib3==2.4.0

    uvicorn==0.34.2

    uvloop==0.21.0

    vllm==0.8.5

    watchfiles==1.0.5

    wcwidth==0.2.13

    websockets==15.0.1

    wrapt==1.17.2

    wsproto==1.2.0

    xformers==0.0.29.post2

    xgrammar==0.1.18

    yarl==1.20.0

    zipp==3.21.0

    '
  post_commands:
  - uv pip install --compile-bytecode flashinfer-python --find-links https://flashinfer.ai/whl/cu124/torch2.6
